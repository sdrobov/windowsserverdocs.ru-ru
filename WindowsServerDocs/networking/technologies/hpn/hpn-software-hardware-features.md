---
title: Программно и аппаратно интегрируемые компоненты и технологии
description: Эти функции содержат как программные, так и аппаратные компоненты. Программное обеспечение тесно связано с возможностями оборудования, необходимыми для работы функции. К таким примерам относятся ВММК, VMQ, разгрузка контрольной суммы IPv4 на стороне отправки и RSS.
ms.prod: windows-server
ms.technology: networking
ms.topic: article
ms.assetid: 0cafb1cc-5798-42f5-89b6-3ffe7ac024ba
manager: dougkim
ms.author: pashort
author: shortpatti
ms.date: 09/12/2018
ms.openlocfilehash: f032717b9f4dca65454d8251083b73ff2d57dba7
ms.sourcegitcommit: 6aff3d88ff22ea141a6ea6572a5ad8dd6321f199
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/27/2019
ms.locfileid: "71355319"
---
# <a name="software-and-hardware-sh-integrated-features-and-technologies"></a>Программно и аппаратно интегрируемые компоненты и технологии

Эти функции содержат как программные, так и аппаратные компоненты. Программное обеспечение тесно связано с возможностями оборудования, необходимыми для работы функции. К таким примерам относятся ВММК, VMQ, разгрузка контрольной суммы IPv4 на стороне отправки и RSS.

>[!TIP]
>Функции SH и ПРИНЕС доступны, если установленный сетевой адаптер поддерживает ее. В описании функций ниже рассказывается, как определить, поддерживает ли ваш сетевой адаптер эту функцию.

## <a name="converged-nic"></a>Конвергенция сетевого адаптера 

Конвергенция сетевых адаптеров — это технология, позволяющая виртуальным сетевым адаптерам на узле Hyper-V предоставлять службы RDMA для размещения процессов. Windows Server 2016 больше не требует отдельных сетевых адаптеров для RDMA. Функция конвергенции сетевых адаптеров позволяет виртуальным сетевым адаптерам в разделе узла (vNIC) предоставлять RDMA разделу узла и совместно использовать пропускную способность сетевых карт между трафиком RDMA и виртуальной машиной и другим трафиком TCP/UDP.

![Конвергенция сетевого адаптера с помощью SDN](../../media/Converged-NIC/conv-nic-sdn.png)

Вы можете управлять работой с сетевыми картами с помощью VMM или Windows PowerShell. Командлеты PowerShell — это те же командлеты, которые используются для RDMA (см. ниже).

Чтобы использовать функцию конвергенции сетевых адаптеров, выполните следующие действия.

1.  Убедитесь, что для узла установлен параметр DCB.

2.  Обязательно включите RDMA на сетевом адаптере или в случае команды SET, сетевые карты привязаны к коммутатору Hyper-V. 

3.  Убедитесь, что на vNIC, назначенном для RDMA на узле, включен параметр RDMA. 

Дополнительные сведения о RDMA и SET см. в разделе [Удаленный доступ к памяти (RDMA) и включение объединения внедренных команд (Set)](https://docs.microsoft.com/windows-server/virtualization/hyper-v-virtual-switch/rdma-and-switch-embedded-teaming).

## <a name="data-center-bridging-dcb"></a>Мост для центра обработки данных 

DCB — это набор стандартов для инженеров по стандартизации и электронике (IEEE), обеспечивающий согласованные структуры в центрах обработки данных. Диспетчер DCB обеспечивает управление пропускной способностью на основе очередей оборудования на узле с совместным использованием смежного коммутатора. Весь трафик для хранилища, сети данных, межпроцессного взаимодействия с кластером (IPC) и управления совместно используют одну и ту же инфраструктуру сети Ethernet. В Windows Server 2016 DCB может применяться к любым сетевым картам по отдельности и к сетевым адаптерам, привязанным к коммутатору Hyper-V.

Для DCB Windows Server использует управление потоком на основе приоритета (коэффициент мощности), стандартизованное в стандарте IEEE 802.1 КББ. Коэффициент мощности создает (почти) сетевую структуру без потерь, предотвращая переполнение в классах трафика. Windows Server также использует расширенный выбор передачи (ETS), стандартизованный в стандарте IEEE 802.1 Каз. ETS позволяет отделить пропускную способность в зарезервированных частях до восьми классов трафика. Каждый класс трафика имеет собственную очередь передачи и при помощи коэффициента компенсаций может запускать и прекращать передачу внутри класса.

Дополнительные сведения см. в статье [мосты центров обработки данных (DCB)](https://docs.microsoft.com/windows-server/networking/technologies/dcb/dcb-top).

## <a name="hyper-v-network-virtualization"></a>Виртуализация сети Hyper-V

|                            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|----------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|       **v1 (HNVv1)**       |                     В Windows Server 2012 виртуализация сети Hyper-V (HNV) обеспечивает виртуализацию сетей клиентов поверх общей, физической сетевой инфраструктуры. Благодаря минимальным изменениям, необходимым в структуре физической сети, HNV предоставляет поставщикам услуг гибкость для развертывания и переноса рабочих нагрузок клиента в любом месте в трех облаках: в облаке поставщика услуг, частном облаке или Microsoft Azure общедоступном облаке.                     |
| **v2 NVGRE (HNVv2 NVGRE)** | В Windows Server 2016 и System Center Virtual Machine Manager Корпорация Майкрософт предоставляет комплексное решение для виртуализации сети, включающее шлюз RAS, программную балансировку нагрузки, сетевой контроллер и т. д. Дополнительные сведения см. [в статье Обзор виртуализации сети Hyper-V в Windows Server 2016](https://technet.microsoft.com/windows-server-docs/networking/sdn/technologies/hyper-v-network-virtualization/hyperv-network-virtualization-overview-windows-server). |
| **v2 Вкслан (HNVv2 Вкслан)** |                                                                                                                                                                                        В Windows Server 2016 входит в состав SDN-Extension, управляемого через сетевой контроллер.                                                                                                                                                                                        |

---

## <a name="ipsec-task-offload-ipsecto"></a>Разгрузка задач IPsec (Ипсекто) 

Разгрузка задач IPsec — это функция сетевого интерфейса, которая позволяет операционной системе использовать процессор на сетевом адаптере для работы шифрования IPsec.

>[!IMPORTANT] 
>Разгрузка задач IPsec — это устаревшая технология, которая не поддерживается большинством сетевых адаптеров и где она существует, по умолчанию отключена.

## <a name="private-virtual-local-area-network-pvlan"></a>Частная виртуальная локальная сеть (PVLAN). 

Частные виртуальные ЛС разрешают обмен данными только между виртуальными машинами на одном сервере виртуализации. Частная виртуальная сеть не привязана к физическому сетевому адаптеру. Частная виртуальная сеть изолирована от всего внешнего сетевого трафика на сервере виртуализации, а также от любого сетевого трафика между операционной системой управления и внешней сетью. Сеть этого типа полезна, если нужно создать изолированную сетевую среду, например изолированный тестовый домен. Стеки Hyper-V и SDN поддерживают только режим изолированного порта PVLAN.

Дополнительные сведения об изоляции PVLAN см. [в разделе System Center: Блог](https://blogs.technet.microsoft.com/scvmm/2013/06/04/logical-networks-part-iv-pvlan-isolation/)Virtual Machine Manager инженеров.

## <a name="remote-direct-memory-access-rdma"></a>Удаленный доступ к памяти (RDMA) 

RDMA — это сетевая технология, обеспечивающая высокую пропускную способность и скорость обмена данными с низкой задержкой, которая сокращает загрузку ЦП. RDMA поддерживает сетевые подключения без копирования, позволяя сетевому адаптеру передавать данные непосредственно в память приложения или из нее. Возможность RDMA означает, что сетевая карта (физическая или виртуальная) может предоставлять RDMA клиенту RDMA. С другой стороны, с поддержкой RDMA, это означает, что сетевая карта с поддержкой RDMA предоставляет интерфейс RDMA в стеке.

Дополнительные сведения о RDMA см. в разделе [Удаленный доступ к памяти (RDMA) и включение объединения внедренных команд (Set)](https://docs.microsoft.com/windows-server/virtualization/hyper-v-virtual-switch/rdma-and-switch-embedded-teaming).

## <a name="receive-side-scaling-rss"></a>Receive Side Scaling (RSS) 

RSS — это функция сетевого интерфейса, которая разделяет различные наборы потоков и доставляет их различным процессорам для обработки. RSS параллелизуются сетевую обработку, позволяя узлу масштабироваться до очень высоких скоростей данных. 

Дополнительные сведения см. в разделе [масштабирование на стороне приема (RSS)](https://docs.microsoft.com/windows-hardware/drivers/network/introduction-to-receive-side-scaling).

## <a name="single-root-input-output-virtualization-sr-iov"></a>Виртуализация входных данных одного корня (SR-IOV) 

SR-IOV позволяет трафику виртуальной машины перемещаться непосредственно с сетевого адаптера на виртуальную машину без передачи узла Hyper-V. SR-IOV — это неудивительное улучшение производительности виртуальной машины, но не позволяет узлу управлять этим каналом. Используйте SR-IOV только в том случае, если Рабочая нагрузка правильно настроена, является доверенной и является единственной виртуальной машиной на узле.

Трафик, использующий SR-IOV, обходит коммутатор Hyper-V, что означает, что любые политики, например, ACL или управление пропускной способностью, не будут применяться. Трафик SR-IOV также не может быть передан через любую возможность виртуализации сети, поэтому невозможно применить инкапсуляцию NV-GRE или Вкслан. Используйте SR-IOV для хорошо доверенных рабочих нагрузок в конкретных ситуациях. Кроме того, нельзя использовать политики узла, управление пропускной способностью и технологии виртуализации.

В будущем две технологии позволили SR-IOV: Универсальные таблицы потоков (ГФТ) и аппаратная разгрузка QoS (Управление пропускной способностью в сетевой карте) — как только сетевые карты в нашей экосистеме поддерживают их. Сочетание этих двух технологий делает SR-IOV полезным для всех виртуальных машин, позволяя применять политики, виртуализацию и правила управления пропускной способностью, а также может привести к тому, что в общем приложении SR-IOV будут использоваться значительные возможности.

Дополнительные сведения см. в [статье Обзор виртуализации с одним корневым диском ввода-вывода (SR-IOV)](https://docs.microsoft.com/windows-hardware/drivers/network/overview-of-single-root-i-o-virtualization--sr-iov-).

## <a name="tcp-chimney-offload"></a>Разгрузка TCP Chimney

Разгрузка TCP Chimney, также известная как разгрузка обработчика TCP (НОЛИКИ), — это технология, позволяющая узлу разгружать всю обработку TCP в сетевую карту. Так как стек TCP сервера Windows Server почти всегда более эффективен, чем механизм работы с серверами, использовать разгрузку TCP Chimney не рекомендуется.

>[!IMPORTANT]
>Разгрузка TCP Chimney является устаревшей технологией. Мы рекомендуем не использовать разгрузку TCP Chimney, так как корпорация Майкрософт может больше не поддерживать ее в будущем.

## <a name="virtual-local-area-network-vlan"></a>Виртуальная локальная сеть (VLAN) 

Виртуальная ЛС — это расширение заголовка кадра Ethernet для включения секционирования локальной сети в несколько виртуальных ЛС, каждый из которых использует собственное адресное пространство. В Windows Server 2016 виртуальные ЛС устанавливаются на портах коммутатора Hyper-V или при помощи командных интерфейсов в командах объединения сетевых карт. Дополнительные сведения см. в разделе [Объединение сетевых карт и виртуальные локальные сети (VLAN)](https://docs.microsoft.com/windows-server/networking/technologies/nic-teaming/nict-and-vlans).

## <a name="virtual-machine-queue-vmq"></a>с очередью виртуальной машины (VMQ). 

ВМКС — это функция сетевого интерфейса, которая выделяет очередь для каждой виртуальной машины. Когда Hyper-V включен; также необходимо включить VMQ. В Windows Server 2016 ВМКС использовать NIC Switch Впортс с одной очередью, назначенной впорт, для предоставления тех же функций. Дополнительные сведения см. в статье [виртуальное масштабирование на стороне приема (vRSS)](https://docs.microsoft.com/windows-server/networking/technologies/vrss/vrss-top) и [Объединение сетевых карт](https://docs.microsoft.com/windows-server/networking/technologies/nic-teaming/nic-teaming).

## <a name="virtual-machine-multi-queue-vmmq"></a>Виртуальная машина с несколькими очередями (ВММК) 

ВММК — это функция сетевого интерфейса, позволяющая распределять трафик между виртуальными машинами по нескольким очередям, которые обрабатываются другим физическим процессором. Затем трафик передается на несколько LPs на виртуальной машине, как в vRSS, что позволяет обеспечить значительный объем пропускной способности сети для виртуальной машины.

---